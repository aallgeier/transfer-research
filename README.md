## Part of transfer learning research code
Purpose of posted code: We were interested in whether ResNet classifies a car damage location based on the actual damage location or the photo angle. For example, does the classifier know that there is a damage on the side of a car because it actually recognizes a damage there or because the photo simply shows the side of a car? Is the model learning what we want it to learn?<br>
<br>
Full paper link: https://ieeexplore.ieee.org/document/9844486

<p float="left">
  <img src="fig3" width="400" />
</p>

## Acknowledgements
My code is largely based on the PyTorch tutorials below:<br>
https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html<br>
https://pytorch.org/tutorials/beginner/basics/data_tutorial.html<br>
It is a combination of lines directly from the above tutorials (or slightly modified) and my own. Also inspired by the fine_tune() method from fast.ai


